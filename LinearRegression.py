# -*- coding: utf-8 -*-
"""part1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CeUe5iZH-dZl8kpUb3mbTwJEieQdPpNH
"""


pip install ucimlrepo

from ucimlrepo import fetch_ucirepo
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_squared_error
import matplotlib.pyplot as plt
import seaborn as sns
import itertools

#Load dataset
student_perf = fetch_ucirepo(id=320)
df = pd.concat([student_perf.data.features, student_perf.data.targets], axis=1)

#Remove duplicates
df = df.drop_duplicates()

#Remove rows with missing values
df = df.dropna()

#Turncategorical variables to numerical ones
df_encoded = pd.get_dummies(df, drop_first=True)

#Filter features with |correlation with G3| > 0.15
correlations = df_encoded.corr(numeric_only=True)['G3'].drop('G3')
selected_features = correlations[correlations.abs() > 0.15].index.tolist()

print("Features selected (|corr| > 0.15):")
print(selected_features)

#Select features and target
X = df_encoded[selected_features]
y = df_encoded['G3'].values.reshape(-1, 1)

# Correlation Heatmap for Selected Features + G3
heatmap_features = selected_features + ['G3']
plt.figure(figsize=(10, 8))
sns.heatmap(df_encoded[heatmap_features].corr().round(2), annot=True, cmap='coolwarm', linewidths=0.5)
plt.title("Correlation Heatmap: Selected Features and G3")
plt.tight_layout()
plt.show()

# Scatter Plots for G1 vs G3 and G2 vs G3
if 'G1' in df_encoded.columns and 'G2' in df_encoded.columns:

    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1)
    sns.scatterplot(x=df_encoded['G1'], y=df_encoded['G3'])
    plt.title("G1 vs G3")
    plt.xlabel("G1 (First Period Grade)")
    plt.ylabel("G3 (Final Grade)")

    plt.subplot(1, 2, 2)
    sns.scatterplot(x=df_encoded['G2'], y=df_encoded['G3'])
    plt.title("G2 vs G3")
    plt.xlabel("G2 (Second Period Grade)")
    plt.ylabel("G3 (Final Grade)")

    plt.tight_layout()
    plt.show()

#Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Normalize features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Add bias term
X_train_b = np.c_[np.ones((X_train_scaled.shape[0], 1)), X_train_scaled]
X_test_b = np.c_[np.ones((X_test_scaled.shape[0], 1)), X_test_scaled]

# Gradient Descent function
def gradient_descent(X, y, learning_rate=0.05, n_iterations=3000):
    m, n = X.shape
    theta = np.zeros((n, 1))
    for _ in range(n_iterations):
        gradients = 2/m * X.T @ (X @ theta - y)
        theta -= learning_rate * gradients
    return theta

#Evaluation functions
def evaluate_r2(X, y, theta):
    y_pred = X @ theta
    return r2_score(y, y_pred)

def evaluate_mse(X, y, theta):
    y_pred = X @ theta
    return mean_squared_error(y, y_pred)

# Best Learning Rate
learning_rates = [0.001, 0.01, 0.05, 0.1]
iterations_list = [500, 1000, 2000, 3000]

best_r2 = -np.inf
best_mse = np.inf
best_theta = None
best_params = None

print("LearningRate\tIterations\tR²\t\tMSE")
for lr, iters in itertools.product(learning_rates, iterations_list):
    theta = gradient_descent(X_train_b, y_train, learning_rate=lr, n_iterations=iters)
    r2 = evaluate_r2(X_test_b, y_test, theta)
    mse = evaluate_mse(X_test_b, y_test, theta)
    print(f"{lr:.3f}\t\t{iters}\t\t{r2:.7f}\t\t{mse:.7f}")
    if r2 > best_r2:
        best_r2 = r2
        best_mse = mse
        best_theta = theta
        best_params = (lr, iters)

# Report best results
print("\nBest Model Performance on Test Set:")
print(f"Learning Rate: {best_params[0]}")
print(f"Iterations: {best_params[1]}")
print(f"R² Score: {best_r2:.4f}")
print(f"MSE: {best_mse:.4f}")

#Step 14: Predicted vs Actual Plot for Best Model
y_pred_best = X_test_b @ best_theta
plt.figure(figsize=(6, 6))
sns.scatterplot(x=y_test.flatten(), y=y_pred_best.flatten())
plt.plot([0, 20], [0, 20], color='red', linestyle='--')  # ideal line
plt.xlabel("Actual G3")
plt.ylabel("Predicted G3")
plt.title("Predicted vs Actual G3")
plt.tight_layout()
plt.show()